<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<title>Music Assistant</title>
</head>
<body>
<h1>NetEase Cloud Music Assistant</h1>

<button id="startRecordingButton">Start Talking</button>
<button id="stopRecordingButton" disabled>Stop Talking</button>

<div id="info"></div>
<br>
<div style="background-color: #f2f2f2; border-radius: 5px; padding: 20px; box-shadow: 0px 0px 10px #888888;" id="resultDisplay">Dialog History</div>

  <script>
      var start = 0;
      var SAMPLE_RATE = 44100;

      String.prototype.toHHMMSS = function() {
        var sec_num = parseInt(this, 10); // don't forget the second param
        var hours = Math.floor(sec_num / 3600);
        var minutes = Math.floor((sec_num - hours * 3600) / 60);
        var seconds = sec_num - hours * 3600 - minutes * 60;

        if (hours < 10) {
          hours = "0" + hours;
        }
        if (minutes < 10) {
          minutes = "0" + minutes;
        }
        if (seconds < 10) {
          seconds = "0" + seconds;
        }
        return hours + ":" + minutes + ":" + seconds;
      };

      const startRecordingButton = document.getElementById("startRecordingButton");
      const stopRecordingButton = document.getElementById("stopRecordingButton");
      const resultDisplay = document.getElementById('resultDisplay');

      var leftchannel = [];
      var rightchannel = [];
      var recorder = null;
      var recordingLength = 0;
      var volume = null;
      var mediaStream = null;
      var context = null;
      var blob = null;
      var wakeup = Boolean(false);

      startRecordingButton.addEventListener("click", function() {
        start = new Date().getTime();
        // Initialize recorder
        // navigator.getUserMedia =navigator.getUserMedia ||navigator.webkitGetUserMedia ||navigator.mozGetUserMedia ||navigator.msGetUserMedia;

        navigator.getUserMedia(
          {
            // audio: true
            audio: {
              sampleRate: SAMPLE_RATE,
              channelCount: 2 // canary 中此设置未生效，始终为 2
            }
          },

          function(e) {
            console.log("user consent");

            // creates the audio context
            // window.AudioContext =
            //   window.AudioContext || window.webkitAudioContext;
            context = new AudioContext({sampleRate: SAMPLE_RATE});

            // creates an audio node from the microphone incoming stream
            mediaStream = context.createMediaStreamSource(e);

            // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createScriptProcessor
            // bufferSize: the onaudioprocess event is called when the buffer is full
            var bufferSize = 2048;
            var numberOfInputChannels = 2;
            var numberOfOutputChannels = 2;
            if (context.createScriptProcessor) {
              recorder = context.createScriptProcessor(
                bufferSize,
                numberOfInputChannels,
                numberOfOutputChannels
              );
            } else {
              recorder = context.createJavaScriptNode(
                bufferSize,
                numberOfInputChannels,
                numberOfOutputChannels
              );
            }

            recorder.onaudioprocess = function(e) {
              leftchannel.push(
                new Float32Array(e.inputBuffer.getChannelData(0))
              );
              rightchannel.push(
                new Float32Array(e.inputBuffer.getChannelData(1))
              );
              recordingLength += bufferSize;
            };

            // we connect the recorder
            mediaStream.connect(recorder);
            recorder.connect(context.destination);
          },
          function(e) {
            console.error(e);
          }
        );

        startRecordingButton.disabled = true;
        stopRecordingButton.disabled = false;

      });

      stopRecordingButton.addEventListener("click", function() {
          info.textContent = String((new Date().getTime()-start)/1000).toHHMMSS();
        // window.AudioContext = window.AudioContext || window.webkitAudioContext;

        // stop recording
        recorder.disconnect(context.destination);
        mediaStream.disconnect(recorder);

        // we flat the left and right channels down
        // Float32Array[] => Float32Array
        var leftBuffer = flattenArray(leftchannel, recordingLength);
        var rightBuffer = flattenArray(rightchannel, recordingLength);
        // we interleave both channels together
        // [left[0],right[0],left[1],right[1],...]
        var interleaved = interleave(leftBuffer, rightBuffer);

        // we create our wav file
        var buffer = new ArrayBuffer(44 + interleaved.length * 2);
        var view = new DataView(buffer);

        // RIFF chunk descriptor
        writeUTFBytes(view, 0, "RIFF");
        view.setUint32(4, 44 + interleaved.length * 2, true);
        writeUTFBytes(view, 8, "WAVE");
        // FMT sub-chunk
        writeUTFBytes(view, 12, "fmt ");
        view.setUint32(16, 16, true); // chunkSize
        view.setUint16(20, 1, true); // wFormatTag
        view.setUint16(22, 2, true); // wChannels: stereo (2 channels)
        view.setUint32(24, 44100, true); // dwSamplesPerSec
        view.setUint32(28, 44100 * 4, true); // dwAvgBytesPerSec
        view.setUint16(32, 4, true); // wBlockAlign
        view.setUint16(34, 16, true); // wBitsPerSample
        // data sub-chunk
        writeUTFBytes(view, 36, "data");
        view.setUint32(40, interleaved.length * 2, true);

        // write the PCM samples
        var index = 44;
        var volume = 1;
        for (var i = 0; i < interleaved.length; i++) {
          view.setInt16(index, interleaved[i] * (0x7fff * volume), true);
          index += 2;
        }

        // our final blob
        blob = new Blob([view], { type: "audio/wav" });

        // 发送音频数据到后端
        const formData = new FormData();

        formData.append('audio', blob, 'recording.wav');

        fetch('/wakeup', {
          method: 'POST',
          body: formData
        })
          .then(response => response.json())
          .then(data => {
            console.log(data.result);
            const lineBreak = document.createElement('br');
            resultDisplay.appendChild(lineBreak);
            const resultText = document.createTextNode('我 :'+ data.text);
            resultDisplay.appendChild(resultText);
            const lineBreak2 = document.createElement('br');
            resultDisplay.appendChild(lineBreak2);
            const outputText = document.createTextNode('网易精灵 :'+ data.output);
            resultDisplay.appendChild(outputText);
          })
          .catch(error => {
            console.error('Error sending audio data to server:', error);
          });

        if(wakeup){
          fetch('/upload', {
            method: 'POST',
            body: formData
          })
            .then(response => response.json())
            .then(data => {
              console.log(data.result);
              const lineBreak = document.createElement('br');
              resultDisplay.appendChild(lineBreak);
              const resultText = document.createTextNode('我 :'+ data.text);
              resultDisplay.appendChild(resultText);
              const lineBreak2 = document.createElement('br');
              resultDisplay.appendChild(lineBreak2);
              const outputText = document.createTextNode('网易精灵 :'+ data.output);
              resultDisplay.appendChild(outputText);
            })
            .catch(error => {
              console.error('Error sending audio data to server:', error);
            });
        }

        leftchannel = [];
        rightchannel = [];

        startRecordingButton.disabled = false;
        stopRecordingButton.disabled = true;

      });


      function flattenArray(channelBuffer, recordingLength) {
        var result = new Float32Array(recordingLength);
        var offset = 0;
        for (var i = 0; i < channelBuffer.length; i++) {
          var buffer = channelBuffer[i];
          result.set(buffer, offset);
          offset += buffer.length;
        }
        return result;
      }

      function interleave(leftChannel, rightChannel) {
        var length = leftChannel.length + rightChannel.length;
        var result = new Float32Array(length);

        var inputIndex = 0;

        for (var index = 0; index < length; ) {
          result[index++] = leftChannel[inputIndex];
          result[index++] = rightChannel[inputIndex];
          inputIndex++;
        }
        return result;
      }

      function writeUTFBytes(view, offset, string) {
        for (var i = 0; i < string.length; i++) {
          view.setUint8(offset + i, string.charCodeAt(i));
        }
      }
  </script>
</body>
</html>
